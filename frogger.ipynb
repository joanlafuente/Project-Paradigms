{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":["VT0AJBV4DVG9","zWebh6GnDVG-","4Elow1ouwp0K"],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"eeb792fe36684cf381098d9a1fe10937":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_77ae47de502545258a122371814740c1","IPY_MODEL_c3989959925c4094b988693f180d4e66"],"layout":"IPY_MODEL_beb2021d98c944b8b6fd9e67cfb11b23"}},"77ae47de502545258a122371814740c1":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a734381155364eb991a257db52601a99","placeholder":"​","style":"IPY_MODEL_270ddcf2cb30473e8f5ae932dd062257","value":"0.404 MB of 0.404 MB uploaded\r"}},"c3989959925c4094b988693f180d4e66":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_211d1749c096463ca8cd657b9530540a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_330c43fdaa134c43831dc2cbe233a220","value":1}},"beb2021d98c944b8b6fd9e67cfb11b23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a734381155364eb991a257db52601a99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"270ddcf2cb30473e8f5ae932dd062257":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"211d1749c096463ca8cd657b9530540a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"330c43fdaa134c43831dc2cbe233a220":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb173389c5814c098ba4164b723f8b50":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_9d8c8d6954f14bd1a9e4c29a94a9ddf9","IPY_MODEL_8235f8318fe24a578f8423cdc161bac6"],"layout":"IPY_MODEL_deee6c5a709f4d9bace683068332be09"}},"9d8c8d6954f14bd1a9e4c29a94a9ddf9":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51f5253bae714fd0af4544be00e8afc4","placeholder":"​","style":"IPY_MODEL_009a5235f8b646a4be52a0c134e65d64","value":"0.318 MB of 0.318 MB uploaded\r"}},"8235f8318fe24a578f8423cdc161bac6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b24770136d124706b852e75db3197d02","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed395f957c834f9598e245e996d40743","value":1}},"deee6c5a709f4d9bace683068332be09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51f5253bae714fd0af4544be00e8afc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"009a5235f8b646a4be52a0c134e65d64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b24770136d124706b852e75db3197d02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed395f957c834f9598e245e996d40743":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c47cb61ca8a64fd8912519f3a939d4a9":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_8ba81997b7eb49699013fddac0ffa13e","IPY_MODEL_12125900553f4f9aa876c9fecc932e1c"],"layout":"IPY_MODEL_4f6271c6a3cf42639381902468d0e73a"}},"8ba81997b7eb49699013fddac0ffa13e":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad941d0ab19f4f049256d111e40e1be0","placeholder":"​","style":"IPY_MODEL_0573f83e8cfb4052891dfd5d5fef70f6","value":"0.343 MB of 0.343 MB uploaded\r"}},"12125900553f4f9aa876c9fecc932e1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_50a5ee1c9d764b4dbcfc7cc98a00fd1e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b45d0ecacdce4b9e9c6e077d71abe2f5","value":1}},"4f6271c6a3cf42639381902468d0e73a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad941d0ab19f4f049256d111e40e1be0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0573f83e8cfb4052891dfd5d5fef70f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50a5ee1c9d764b4dbcfc7cc98a00fd1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b45d0ecacdce4b9e9c6e077d71abe2f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install the ALE package\n!pip install ale-py\n!pip install gymnasium==1.0.0\n!pip install stable_baselines3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P0OI9mQrDVG8","outputId":"9a57f9ed-63db-463c-e0f1-368a80b25919","trusted":true,"execution":{"iopub.status.busy":"2024-12-06T22:47:18.654986Z","iopub.execute_input":"2024-12-06T22:47:18.655700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gymnasium as gym\nfrom gymnasium.wrappers import MaxAndSkipObservation, ResizeObservation, GrayscaleObservation, FrameStackObservation, ReshapeObservation\nfrom stable_baselines3.common.atari_wrappers import NoopResetEnv, MaxAndSkipEnv, FireResetEnv, EpisodicLifeEnv\nimport ale_py\nimport cv2\nfrom gymnasium.spaces import Box","metadata":{"id":"uBf7PeJxDVG9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0fea5483-3a48-4d5a-ff17-ce632644478d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ENV_NAME = \"ALE/Frogger-v5\"","metadata":{"id":"rT_16NzPDVG9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"83a402ce-edfe-4d8b-8fe3-32696b0996e6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Enviroment preparation","metadata":{"id":"VT0AJBV4DVG9"}},{"cell_type":"code","source":"class ScaledFloatFrame(gym.ObservationWrapper):\n    def observation(self, obs):\n        return np.array(obs).astype(np.float32) / 255.0\n\n\ndef make_env(env_name):\n    env = gym.make(env_name, obs_type=\"grayscale\")\n    env = FireResetEnv(env)\n    print(\"Standard Env.        : {}\".format(env.observation_space.shape))\n    env = MaxAndSkipObservation(env, skip=4)\n    print(\"MaxAndSkipObservation: {}\".format(env.observation_space.shape))\n    #env = FireResetEnv(env)\n    env = ResizeObservation(env, (84, 84))\n    print(\"ResizeObservation    : {}\".format(env.observation_space.shape))\n    env = FrameStackObservation(env, stack_size=4)\n    print(\"FrameStackObservation: {}\".format(env.observation_space.shape))\n    env = ScaledFloatFrame(env)\n    print(\"ScaledFloatFrame     : {}\".format(env.observation_space.shape))\n\n    return env\n\n\nenv = make_env(ENV_NAME)\nprint(\"\\nAction space is {} \".format(env.action_space))\nprint(\"Observation space is {} \".format(env.observation_space))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9UJtQbOZDVG9","outputId":"0e678dbf-0f5f-43aa-a838-3d1fe1019a59","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FrameStackObservation(gym.Wrapper):\n    def __init__(self, env, stack_size):\n        \"\"\"Constructor\"\"\"\n        gym.Wrapper.__init__(self, env)\n        self.stack_size = stack_size\n        self.frames = deque([], maxlen=stack_size)\n        shp = env.observation_space.shape\n        self.observation_space = Box(0.0, 1.0, (stack_size, shp[0], shp[1]), dtype=np.float32)\n\n    def reset(self, **kwargs):\n        \"\"\"Reset the environment\"\"\"\n        observation, info = self.env.reset()\n        for _ in range(self.stack_size):\n            self.frames.append(observation)\n        return self._get_observation(), info\n\n    def step(self, action):\n        \"\"\"Take a step\"\"\"\n        observation, reward, done, truncated, info = self.env.step(action)\n        self.frames.append(observation)\n        return self._get_observation(), reward, done, truncated, info\n\n    def _get_observation(self):\n        \"\"\"Get the observation\"\"\"\n        frames_list = [frame for frame in self.frames]\n        return np.stack(frames_list, axis=0)\n\nclass ScaleAndReshapeObservation(gym.ObservationWrapper):\n    def __init__(self, env):\n        \"\"\"Constructor\"\"\"\n        gym.ObservationWrapper.__init__(self, env)\n        self.observation_space = Box(0.0, 1.0, env.observation_space.shape, dtype=np.float32)\n\n    def observation(self, observation):\n        \"\"\"Observation\"\"\"\n        if type(observation) == tuple:\n            observation, info = observation\n\n            observation = cv2.resize(observation, (84, 84))\n            return (np.array(observation).astype(np.float32) / 255.0, info)\n        else:\n            observation = cv2.resize(observation, (84, 84))\n            return np.array(observation).astype(np.float32) / 255.0\n\n\ndef preprocess_env(env_name):\n\n    env = gym.make(env_name, obs_type=\"grayscale\", render_mode='rgb_array')\n    env = NoopResetEnv(env, noop_max=4)\n    env = MaxAndSkipEnv(env, skip=2)\n    env = FireResetEnv(env)\n    env = EpisodicLifeEnv(env)\n    env = ScaleAndReshapeObservation(env)\n    env = FrameStackObservation(env, stack_size=4)\n\n    return env","metadata":{"id":"1d4KNSrdlPsV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env = preprocess_env(ENV_NAME)\nprint(\"\\nAction space is {} \".format(env.action_space))\nprint(\"Observation space is {} \".format(env.observation_space))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xLDGqzvslVnl","outputId":"564a4816-139f-48f4-97eb-66dc88230c31","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### DQN Aproach","metadata":{"id":"XlTAr0lNDVG9"}},{"cell_type":"code","source":"class DuelingDQN(nn.Module):\n    def __init__(self, input_shape, output_shape):\n        super(DuelingDQN, self).__init__()\n\n        self.net = nn.Sequential(\n            nn.Conv2d(input_shape[0], 32, kernel_size=5, stride=4),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n            nn.ReLU(),\n            nn.Flatten(),\n            nn.Linear(1600, 512),\n            nn.ReLU()\n        )\n\n        self.value_prediction = nn.Linear(512, 1)\n        self.advantage_prediction = nn.Linear(512, output_shape)\n\n\n    def forward(self, x):\n        embedding = self.net(x)\n        value = self.value_prediction(embedding)\n        advantage = self.advantage_prediction(embedding)\n        q_values = value + advantage - advantage.mean(dim=-1).unsqueeze(-1)\n        return q_values","metadata":{"id":"sP70SugjDVG9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Experience = collections.namedtuple('Experience', field_names=['state', 'action', 'reward', 'done', 'new_state'])\n\nclass Agent:\n    def __init__(self, env, exp_replay_buffer):\n        self.env = env\n        self.exp_replay_buffer = exp_replay_buffer\n        self._reset()\n\n    def _reset(self):\n        self.current_state = self.env.reset()[0]\n        self.total_reward = 0.0\n\n    def step(self, net, target_net, epsilon=0.0, device=\"cpu\"):\n        done_reward = None\n        if np.random.random() < epsilon:\n            action = env.action_space.sample()\n        else:\n            state_ = np.array([self.current_state])\n            state = torch.tensor(state_).to(device)\n            q_vals = net(state)\n            _, act_ = torch.max(q_vals, dim=1)\n            action = int(act_.item())\n\n        new_state, reward, terminated, truncated, _ = self.env.step(action)\n        is_done = terminated or truncated\n        self.total_reward += reward\n\n        exp = Experience(self.current_state, action, reward, is_done, new_state)\n        self.exp_replay_buffer.append(exp, net, target_net, device)\n        self.current_state = new_state\n\n        if is_done:\n            done_reward = self.total_reward\n            self._reset()\n\n        return done_reward","metadata":{"id":"s8SQUYj4DVG9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def compute_loss(model, target_model, states, actions, rewards, dones, next_states, gamma=0.99, criterion=nn.MSELoss()):\n#     Q_values = model(states).gather(1, actions.unsqueeze(-1)).squeeze(-1)\n\n#     next_state_values = target_model(next_states).max(1)[0]\n#     next_state_values[dones] = 0.0\n#     next_state_values = next_state_values.detach()\n\n#     expected_Q_values = next_state_values * gamma + rewards\n\n#     return criterion(Q_values, expected_Q_values)\n\ndef compute_loss(model, target_model, states, actions, rewards, dones, next_states, gamma=0.99, criterion=nn.MSELoss(), device):\n    # Get the qvals of the DQN network\n    qvals = model(states).gather(1, actions.unsqueeze(-1)).squeeze(-1)\n\n    # Get the best action for the next state given the DQN network\n    actions_next = torch.argmax(model(next_states), dim=1)\n    # Get the qvals of the target network\n    with torch.no_grad():\n        qvals_next = target_model(next_states)\n\n    # Get the qvals of the target network for the best action considering the dqn network\n    qvals_next = torch.tensor(np.array([qvals_next[i][actions_next[i]].cpu() for i in range(len(actions_next))])).to(device)\n\n    qvals_next[dones] = 0\n\n    # Calculate the Bellman equation\n    expected_qvals = rewards + gamma * qvals_next\n\n    # Calculate the loss\n    return criterion(qvals, expected_qvals)","metadata":{"id":"Vo1FgQVDDVG9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_td_error(model, target_model, states, actions, rewards, dones, next_states, gamma=0.99, device=\"cpu\"):\n    states = torch.tensor(states).to(device)\n    actions = torch.tensor(actions).to(device)\n    rewards = torch.tensor(rewards).to(device)\n    dones = torch.tensor(dones).to(device)\n    next_states = torch.tensor(next_states).to(device)\n\n    with torch.no_grad():\n        Q_values = model(states.unsqueeze(0)).gather(1, actions.unsqueeze(0).unsqueeze(-1)).squeeze(-1)\n\n        next_state_values = target_model(next_states.unsqueeze(0)).max(1)[0]\n        next_state_values[dones] = 0.0\n        next_state_values = next_state_values.detach()\n\n        expected_Q_values = next_state_values * gamma + rewards\n\n    return (Q_values - expected_Q_values).abs().detach().item()","metadata":{"id":"tqlWztE9DVG-","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PrioritizedExperienceReplay:\n    \"\"\"\n    D'aquest metode no se si es correcte del tot, en comptes de calcular el\n    td_error quan faig el sampling ho he implementat en el moment en que safegeix al buffer.\n\n    D'aquesta forma no augmenta molt tant al numero de claculs extra (Sino shauria de clacular\n    per a tot el buffer cada vegada que fem sampling)\n    \"\"\"\n    def __init__(self, capacity):\n        self.buffer = collections.deque(maxlen=capacity)\n        self.priorities = collections.deque(maxlen=capacity)\n\n    def __len__(self):\n        return len(self.buffer)\n\n    def append(self, experience, model, target_model, device=\"cpu\"):\n        td_error = compute_td_error(model, target_model, experience.state, experience.action, experience.reward, experience.done, experience.new_state, device=device)\n        self.priorities.append(td_error)\n        self.buffer.append(experience)\n\n    def sample(self, BATCH_SIZE, alpha=0.6, beta=0.4, epsilon=0.01):\n        priorities = np.array(self.priorities)\n        priorities = priorities + epsilon\n        probabilities = priorities ** alpha\n        probabilities = probabilities / probabilities.sum()\n\n        indices = np.random.choice(len(self.buffer), BATCH_SIZE, p=probabilities)\n        weights = (1/len(self.buffer) * 1/probabilities[indices]) ** beta\n        states, actions, rewards, dones, next_states = zip(*[self.buffer[idx] for idx in indices])\n\n        states = torch.from_numpy(np.array(states, dtype=np.float32))\n        actions = torch.from_numpy(np.array(actions, dtype=np.int64))\n        rewards = torch.from_numpy(np.array(rewards, dtype=np.float32))\n        dones = torch.from_numpy(np.array(dones, dtype=bool))\n        next_states = torch.from_numpy(np.array(next_states, dtype=np.float32))\n        weights = torch.from_numpy(np.array(weights, dtype=np.float32))\n\n        return states, actions, rewards, dones, next_states, weights","metadata":{"id":"80IE9lXgDVG-","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Hyperparameters","metadata":{"id":"PyGx30WXDVG-"}},{"cell_type":"code","source":"MEAN_REWARD_BOUND = 350.0\nNUMBER_OF_REWARDS_TO_AVERAGE = 10\n\nGAMMA = 0.99\n\nBATCH_SIZE = 64\nLEARNING_RATE = 0.0001\n\nEXPERIENCE_REPLAY_SIZE = 10000\nSYNC_TARGET_NETWORK = 1000\n\nEPS_START = 1.0\nEPS_DECAY = 0.999987\nEPS_MIN = 0.03","metadata":{"id":"qDdEmUJIDVG-","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nwandb.login()","metadata":{"id":"e9MjsNGvDVG-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"742a42c6-c9f6-4b25-86cf-e32f432866ee","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.init(project=\"Breakout\", name=\"DQN\")\nwandb.config.update({\"gamma\": GAMMA, \"batch_size\": BATCH_SIZE, \"learning_rate\": LEARNING_RATE, \"experience_replay_size\": EXPERIENCE_REPLAY_SIZE, \"sync_target_network\": SYNC_TARGET_NETWORK, \"eps_start\": EPS_START, \"eps_decay\": EPS_DECAY, \"eps_min\": EPS_MIN})","metadata":{"id":"BjCkdIp1DVG-","outputId":"cb566cb6-0aae-4ac6-a045-eb9398958aa1","colab":{"base_uri":"https://localhost:8080/","height":370,"referenced_widgets":["c47cb61ca8a64fd8912519f3a939d4a9","8ba81997b7eb49699013fddac0ffa13e","12125900553f4f9aa876c9fecc932e1c","4f6271c6a3cf42639381902468d0e73a","ad941d0ab19f4f049256d111e40e1be0","0573f83e8cfb4052891dfd5d5fef70f6","50a5ee1c9d764b4dbcfc7cc98a00fd1e","b45d0ecacdce4b9e9c6e077d71abe2f5"]},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env = make_env(ENV_NAME)\n\nnet = DuelingDQN(env.observation_space.shape, env.action_space.n).to(device)\ntarget_net = DuelingDQN(env.observation_space.shape, env.action_space.n).to(device)\n\nbuffer = PrioritizedExperienceReplay(EXPERIENCE_REPLAY_SIZE)\nagent = Agent(env, buffer)\n\nepsilon = EPS_START\noptimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\ncriterion = nn.MSELoss(reduction=\"none\")\ntotal_rewards = []\nframe_number = 0\n\ntbar = tqdm()\nwhile True:\n    frame_number += 1\n    epsilon = max(epsilon * EPS_DECAY, EPS_MIN)\n\n    reward = agent.step(net, target_net, epsilon, device=device)\n    if reward is not None:\n        total_rewards.append(reward)\n\n        mean_reward = np.mean(total_rewards[-NUMBER_OF_REWARDS_TO_AVERAGE:])\n        tbar.set_description(f\"Frame:{frame_number} | Total games:{len(total_rewards)} | Mean reward: {mean_reward:.3f}  (epsilon used: {epsilon:.2f})\")\n        wandb.log({\"epsilon\": epsilon, \"reward_100\": mean_reward, \"reward\": reward}, step=frame_number)\n\n        if mean_reward > MEAN_REWARD_BOUND:\n            print(f\"SOLVED in {frame_number} frames and {len(total_rewards)} games\")\n            break\n\n    if len(buffer) < EXPERIENCE_REPLAY_SIZE:\n        continue\n\n    states, actions, rewards, dones, next_states, weights = buffer.sample(BATCH_SIZE)\n    states, actions, rewards, dones, next_states, weights = states.to(device), actions.to(device), rewards.to(device), dones.to(device), next_states.to(device), weights.to(device)\n\n    loss = compute_loss(net, target_net, states, actions, rewards, dones, next_states, gamma=GAMMA, criterion=criterion)\n    loss = (loss * weights).mean()\n    wandb.log({\"loss\": loss.item()}, step=frame_number)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    if frame_number % SYNC_TARGET_NETWORK == 0:\n        target_net.load_state_dict(net.state_dict())","metadata":{"id":"R9VYQm8CDVG-","outputId":"a9443991-e8cc-47a5-f894-3432f1760c61","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"outputs":[],"execution_count":null}]}